{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Decision_Tree.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"r8Vba0fjDOph"},"source":["import pandas as pd\n","import numpy as np\n","from collections import defaultdict\n","\n","def text_file_retrieve(file):\n","    with open(file) as f:\n","        lines = [line.split() for line in f]\n","    f.close()\n","    lines = np.asarray(lines)\n","    return lines\n","\n","def cross_validation(data):\n","    k_data = np.array_split(data,10)\n","    k_data = np.array(k_data)\n","    return k_data\n","\n","def categoricDataCols(features):\n","    typelabel = {}\n","    typecount = 0\n","    types = []\n","    for i in range(features.shape[1]):\n","      if features[0][i].isalpha():\n","        col = features[:,i]\n","        for i, j in enumerate(col):\n","          if j not in typelabel:\n","            typelabel[j] = typecount\n","            typecount += 1\n","          col[i] = float(typelabel[j])\n","        types.append(i)\n","    return types\n","\n","def dataset_split(dataset, value, column, types):\n","    left = []\n","    right = []\n","    for row in dataset:\n","      if column not in types and row[column] < value:\n","        left.append(row)\n","      elif column in types and row[column] == value:\n","        left.append(row)\n","      else:\n","        right.append(row)\n","    return np.array(left), np.array(right)\n","\n","def find_gini_index(left, right):\n","    gini = 0.0\n","    if len(left) > 0:\n","      gini_left = 0.0\n","      left0 = list(left[:,-1]).count(0)/float(len(left))\n","      left1 = list(left[:,-1]).count(1)/float(len(left))\n","      gini_left += left0*left0\n","      gini_left += left1*left1\n","      gini += (1.0 - gini_left)*(float(len(left))/float(len(left) + len(right)))\n","    if len(right) > 0:\n","      gini_right = 0.0\n","      right0 = list(right[:,-1]).count(0)/float(len(right))\n","      right1 = list(right[:,-1]).count(1)/float(len(right))\n","      gini_right += right0*right0\n","      gini_right += right1*right1\n","      gini += (1.0 - gini_right)*(float(len(right))/float(len(left) + len(right)))\n","    return gini\n","\n","def find_node_split(data, types):\n","    node_split = None\n","    error = float('inf')\n","    for i in range(data.shape[1]-1):\n","      for j in data:\n","        left, right = dataset_split(data, j[i], i, types)\n","        current_gini_score = find_gini_index(left, right)\n","        if current_gini_score < error:\n","          error = current_gini_score\n","          node_split = {'attr': i, 'value': j[i], 'left': left, 'right': right}\n","    return node_split\n","\n","def leaf_nodes(left, right):\n","    zeroes = ones = 0\n","    if len(left) > 0:\n","      zeroes += list(left[:,-1]).count(0)\n","      ones += list(left[:,-1]).count(1)\n","    if len(right) > 0:\n","      zeroes += list(right[:,-1]).count(0)\n","      ones += list(right[:,-1]).count(1)\n","    if zeroes < ones:\n","      return 1 \n","    else:\n","      return 0\n","\n","def decision_tree(node, types):\n","    left = node['left']\n","    node.pop('left', None)\n","    right = node['right']\n","    node.pop('right', None)\n","    if len(left) == 0 or len(right) == 0:\n","      node['left'] = node['right'] = leaf_nodes(left, right)\n","      return node \n","    if len(set(left[:,-1])) == 1:\n","      node['left'] = leaf_nodes(left, [])\n","    else:\n","      node['left'] = decision_tree(find_node_split(left, types), types)\n","    if len(set(right[:,-1])) == 1:\n","      node['right'] = leaf_nodes([], right)\n","    else:\n","      node['right'] = decision_tree(find_node_split(right, types), types)\n","    return node\n","\n","def findRoot(root_node, train, types):\n","    root_node = find_node_split(train, types)\n","    root_node = decision_tree(root_node, types)\n","    return root_node\n","\n","def train_test_data(k_data, i):\n","    train = np.array(np.concatenate([y for (x,y) in enumerate(k_data, 0) if x != i], axis = 0))\n","    test = np.array(k_data[i])\n","    return train, test\n","\n","def predict(node, row):\n","    if row[node['attr']] < node['value']:\n","      if type(node['left']) is not dict:\n","        return node['left']\n","      else:\n","        return predict(node['left'], row)    \n","    if type(node['right']) is not dict:\n","      return node['right']\n","    else:\n","      return predict(node['right'], row)\n","\n","def getPredictedValues(test,predictions, root_node):\n","    for i in test:\n","      predictions.append(predict(root_node, i))\n","    return predictions\n","\n","def getF1Score(f1score, precision, recall):\n","    f1score = ((precision*recall)*0.01*2)/(precision + recall)\n","    return f1score\n","\n","# True Positive - tp\n","# True Negative - tn\n","# False Positive - fp\n","# False Negative - fn\n","\n","def performanceMeasures(i, test, accuracy, precision, recall, predictions):\n","    tp = tn = fp = fn = 0 \n","    classlabel = list(test[:,-1])\n","    for i in range(len(classlabel)):\n","      if classlabel[i] == 1 and  predictions[i] == 1:\n","          tp += 1\n","      elif classlabel[i] == 0 and  predictions[i] == 0:\n","          tn += 1\n","      elif classlabel[i] == 0 and predictions[i] == 1:\n","          fp += 1\n","      else:\n","          fn += 1\n","    accuracy += (float((tp + tn)/(tp + fn + fp + tn)))*10\n","    if (tp+fp) != 0:\n","      precision += (float((tp)/(tp + fp)))*10\n","    if (tp+fn) != 0:\n","      recall += (float((tp)/(tp + fn)))*10\n","    return accuracy, precision, recall\n","\n","def main():\n","    input_file = input(\"Enter the filename: \")\n","    dataset = text_file_retrieve(input_file)\n","    ground_truth = np.array(dataset[:,-1].reshape((len(dataset), 1)), dtype = int)\n","    types = categoricDataCols(dataset[:,0:-1])\n","    features = np.array(dataset[:,0:-1], dtype = float)\n","    data = np.concatenate((features, ground_truth), axis = 1)\n","    data_split = cross_validation(data)\n","    accuracy = precision = recall = f1_score = 0.0\n","    for i in range(10):\n","      predictions = []\n","      train, test = train_test_data(data_split, i)\n","      root_node = {}\n","      root_node = findRoot(root_node, train, types)\n","      predictions = getPredictedValues(test, predictions, root_node)\n","      accuracy, precision, recall = performanceMeasures(i, test, accuracy, precision, recall, predictions)\n","    f1_score = getF1Score(f1_score, precision, recall)\n","    print(\"Accuracy: \"+ str(accuracy))\n","    print(\"Precision: \"+ str(precision))\n","    print(\"Recall: \"+ str(recall))\n","    print(\"F1 score: \"+ str(f1_score))\n","    \n","main()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8YEmE2TjTsHF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WieaApFNk4Mo"},"source":[""],"execution_count":null,"outputs":[]}]}