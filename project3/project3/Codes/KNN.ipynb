{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_final_1220 (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3pharIQvnBr",
        "outputId": "57a20471-e7d7-4821-ed5b-bd9e9090ba45"
      },
      "source": [
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def cross_validation(datapts,gtsplit):\n",
        "    datapts_split = np.array_split((datapts),10)\n",
        "    gtsplit = np.array_split((gtsplit),10)\n",
        "    return datapts_split,gtsplit\n",
        "\n",
        "def inputdata(index,datasplit,gtsplit):\n",
        "  train = np.array(np.vstack([x for i,x in enumerate(datasplit) if i != index]))\n",
        "  trainclasslabel = np.array(np.concatenate([x for i,x in enumerate(gtsplit) if i != index]))\n",
        "  test = np.array(datasplit[index])\n",
        "  testclasslabel = np.array(gtsplit[index])\n",
        "  # print(\"cv train type\",train.dtype)\n",
        "  return train,trainclasslabel,test,testclasslabel\n",
        "\n",
        "#normalization definition\n",
        "def normalize(df):                    #normalizaion function\n",
        "    result = df.copy()\n",
        "    for column in df.columns:\n",
        "        max_value = df[column].max()\n",
        "        min_value = df[column].min()\n",
        "        result[column] = (df[column] - min_value) / (max_value - min_value)\n",
        "    return result\n",
        "\n",
        "def Accuracy(y_true,y_pred):\n",
        "  count = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    if y_pred[i] == y_true[i]:\n",
        "      count +=1\n",
        "  accuracy = count / float(len(y_true))\n",
        "  print(\"accuray:\",accuracy)\n",
        "  return accuracy\n",
        "\n",
        "def Recall(y_true,y_pred):\n",
        "    cm = ConfusionMatrix(y_true,y_pred)\n",
        "    recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
        "    recall = np.mean(recall)\n",
        "    print(\"recall:\",recall) \n",
        "    return recall\n",
        "\n",
        "def Precision(y_true,y_pred):\n",
        "    cm = ConfusionMatrix(y_true,y_pred)\n",
        "    precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
        "    precision = np.mean(precision)\n",
        "    print(\"precision:\",precision)\n",
        "    return precision\n",
        "\n",
        "def fscore(prec,recall):\n",
        "    # cm = ConfusionMatrix(y_true,y_pred)\n",
        "    f1score = 2 * (prec * recall) / (prec + recall)\n",
        "    print(\"f1score:\",f1score)\n",
        "    return f1score\n",
        "\n",
        "def ConfusionMatrix(y_true,y_pred):\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_true = np.asarray(y_true)\n",
        "    target = len(np.unique(y_true))\n",
        "    a = (y_true * target) + y_pred\n",
        "    g = np.sort(a)\n",
        "    sq = target * target\n",
        "    hist, bin_edges = np.histogram(a, bins=range(g[0].astype('int'), g[0].astype('int')+ sq + 1))\n",
        "    hist = np.reshape(hist, (target, target))\n",
        "    return hist\n",
        "\n",
        "\n",
        "def KNN(X_train,X_test,Y_train, k):\n",
        "    n = len(X_test)\n",
        "    dists = np.zeros((n, len(X_train)))\n",
        "    y_pred = np.zeros(n)\n",
        "    dists = np.sqrt((X_test**2).sum(axis=1)[:, np.newaxis] + (X_train**2).sum(axis=1) - 2 * X_test.dot(X_train.T))\n",
        "    for i in range(n):\n",
        "       k_neighbour = []\n",
        "       index_arr = np.argsort(dists[i, :], axis = 0)\n",
        "       k_neighbour = Y_train[index_arr[:k]].tolist()\n",
        "       y_pred[i] = (max(set(k_neighbour), key = k_neighbour.count))\n",
        "  \n",
        "    return y_pred\n",
        "\n",
        "#demo execution\n",
        "# pf1 = pd.read_csv(\"/content/project3_dataset3_train.txt\", delimiter = \"\\t\", header=None)\n",
        "# pf2 = pd.read_csv(\"/content/project3_dataset3_test.txt\", delimiter = \"\\t\", header=None)\n",
        "# x_train = pf1.iloc[:,:-1]\n",
        "# y_train = pf1.iloc[:,-1]\n",
        "# x_test = pf2.iloc[:,:-1]\n",
        "# y_test = pf2.iloc[:,-1]\n",
        "# x_train = x_train.values\n",
        "# y_train = y_train.values\n",
        "# x_test = x_test.values\n",
        "# y_test = y_test.values\n",
        "# k = [2,7,8,9]\n",
        "# for i in k:\n",
        "#   print(\"k =\",i)\n",
        "#   y_pred = KNN(x_train,x_test,y_train,int(i))\n",
        "#   Accuracy(y_test,y_pred)\n",
        "#   prec = Precision(y_test,y_pred)\n",
        "#   rec = Recall(y_test,y_pred)\n",
        "#   fscore(prec,rec)\n",
        "\n",
        "\n",
        "#project dataset exection\n",
        "pf1 = pd.read_csv(\"/content/project3_dataset1.txt\", delimiter = \"\\t\", header=None)      #change the file path for new file\n",
        "\n",
        "features = pf1.iloc[:,:-1]          #train features split\n",
        "train_labels = pf1.iloc[:,-1]\n",
        "k = 3                                                             #change the k value as required\n",
        "#processing to resolve categorical values\n",
        "for index,element in pf1.iteritems():\n",
        "  if element.dtype == np.object:\n",
        "    features = pd.concat([features,pd.get_dummies(element,prefix = index)],axis = 1)\n",
        "    features.drop([index],axis=1,inplace=True)\n",
        "features = features.astype(float)\n",
        "\n",
        "\n",
        "#train labels split\n",
        "features = normalize(features)          #normalizing the train data\n",
        "# print(features)\n",
        "\n",
        "datafold,classfold = cross_validation(features,train_labels)\n",
        "avg_accuracy = avg_precision = avg_recall = avg_f1score = 0\n",
        "for index in range(10):\n",
        "  x_train, y_train, x_test, y_test = inputdata(index,datafold,classfold)\n",
        "  result = KNN(x_train,x_test,y_train,k)\n",
        "  knn_confusion_matrix = ConfusionMatrix(y_test, result)\n",
        "  acc = Accuracy(y_test, result)\n",
        "  prec = Precision(y_test, result)\n",
        "  recall = Recall(y_test, result)\n",
        "  f1score = fscore(prec,recall)\n",
        "  print(\"\\n\")\n",
        "\n",
        "# print(result)\n",
        "  avg_accuracy += acc\n",
        "  avg_precision += prec\n",
        "  avg_recall += recall\n",
        "  avg_f1score += f1score\n",
        "\n",
        "\n",
        "print(\"average accuracy:\",avg_accuracy * 10 )\n",
        "print(\"average pecision:\",avg_precision * 10)\n",
        "print(\"average recall:\",avg_recall * 10)\n",
        "print(\"average f1score:\",avg_f1score * 0.1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuray: 0.9824561403508771\n",
            "precision: 0.9857142857142858\n",
            "recall: 0.9782608695652174\n",
            "f1score: 0.9819734345351044\n",
            "\n",
            "\n",
            "accuray: 0.9473684210526315\n",
            "precision: 0.9316239316239316\n",
            "recall: 0.9455882352941176\n",
            "f1score: 0.938554144264183\n",
            "\n",
            "\n",
            "accuray: 0.9649122807017544\n",
            "precision: 0.9777777777777779\n",
            "recall: 0.9285714285714286\n",
            "f1score: 0.9525395503746878\n",
            "\n",
            "\n",
            "accuray: 0.9824561403508771\n",
            "precision: 0.9864864864864865\n",
            "recall: 0.9761904761904762\n",
            "f1score: 0.9813114754098361\n",
            "\n",
            "\n",
            "accuray: 0.9122807017543859\n",
            "precision: 0.9205882352941177\n",
            "recall: 0.8864864864864865\n",
            "f1score: 0.9032155896714028\n",
            "\n",
            "\n",
            "accuray: 0.9649122807017544\n",
            "precision: 0.96875\n",
            "recall: 0.962962962962963\n",
            "f1score: 0.9658478130617136\n",
            "\n",
            "\n",
            "accuray: 1.0\n",
            "precision: 1.0\n",
            "recall: 1.0\n",
            "f1score: 1.0\n",
            "\n",
            "\n",
            "accuray: 0.9824561403508771\n",
            "precision: 0.9883720930232558\n",
            "recall: 0.9666666666666667\n",
            "f1score: 0.9773988897700238\n",
            "\n",
            "\n",
            "accuray: 0.9473684210526315\n",
            "precision: 0.9482758620689655\n",
            "recall: 0.9516129032258065\n",
            "f1score: 0.9499414519906323\n",
            "\n",
            "\n",
            "accuray: 0.9642857142857143\n",
            "precision: 0.9583333333333333\n",
            "recall: 0.9705882352941176\n",
            "f1score: 0.9644218551461246\n",
            "\n",
            "\n",
            "average accuracy: 96.48496240601503\n",
            "average pecision: 96.65922005322156\n",
            "average recall: 95.6692826425728\n",
            "average f1score: 0.9615204204223708\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}